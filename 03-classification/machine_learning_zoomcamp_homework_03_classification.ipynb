{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0: Installing Prerequisites"
      ],
      "metadata": {
        "id": "Lk9PnQqllTgP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UHo4lXyPlA4l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mutual_info_score"
      ],
      "metadata": {
        "id": "VsxlE3mzlXR2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0.1 Loading Dataset"
      ],
      "metadata": {
        "id": "AnIjKrNclcuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Dataset...\")\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\")\n",
        "print(\"Dataset for homework 3 loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XyslU9vlg5w",
        "outputId": "b4f48778-3339-4afd-8e4a-1f644d260d35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Dataset...\n",
            "Dataset for homework 3 loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying the categorical and numerical columns"
      ],
      "metadata": {
        "id": "K8OW5PGolwvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Dataset shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTdFyrmklpGb",
        "outputId": "0967c061-2859-44c4-dec5-4cfbbbbacde9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (1462, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = list(df.columns[df.dtypes == 'object'])\n",
        "numerical_columns = list(df.columns[df.dtypes != 'object'])\n",
        "print(f\"Categorical columns: {categorical_columns}\")\n",
        "print(f\"Numerical columns: {numerical_columns}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivOx-h8Kl2ZB",
        "outputId": "12a35071-4e8b-442a-866f-836b28f914fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical columns: ['lead_source', 'industry', 'employment_status', 'location']\n",
            "Numerical columns: ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab49sOLumDhM",
        "outputId": "0afa602f-af87-48ae-e2e6-9433dc4995e9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lead_source                 128\n",
            "industry                    134\n",
            "number_of_courses_viewed      0\n",
            "annual_income               181\n",
            "employment_status           100\n",
            "location                     63\n",
            "interaction_count             0\n",
            "lead_score                    0\n",
            "converted                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill missing values"
      ],
      "metadata": {
        "id": "d8BRkcE1l7eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[categorical_columns] = df[categorical_columns].fillna('NA')\n",
        "df[numerical_columns] = df[numerical_columns].fillna(0.0)"
      ],
      "metadata": {
        "id": "JU2RgWzal-lZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values after handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCh_pUJ2mBLK",
        "outputId": "9ee799d2-1854-474a-9068-b236af64451a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after handling:\n",
            "lead_source                 0\n",
            "industry                    0\n",
            "number_of_courses_viewed    0\n",
            "annual_income               0\n",
            "employment_status           0\n",
            "location                    0\n",
            "interaction_count           0\n",
            "lead_score                  0\n",
            "converted                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Mode for industry"
      ],
      "metadata": {
        "id": "97YDVATqmJ8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "industry_mode = df['industry'].mode()[0]\n",
        "print(f\"Most frequent observation (mode) for 'industry': {industry_mode}\")\n",
        "print(f\"Answer Q1: {industry_mode}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVl81dbCmO4m",
        "outputId": "b1a9f4fc-8e0d-46d5-cb41-3b9972614237"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent observation (mode) for 'industry': retail\n",
            "Answer Q1: retail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2: Biggest Correlation"
      ],
      "metadata": {
        "id": "q4WgulzsmR9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = ['number_of_courses_viewed', 'annual_income',\n",
        "                      'interaction_count', 'lead_score', 'converted']\n",
        "correlation_matrix = df[numerical_features].corr()\n",
        "print(\"Correlation Matrix:\")\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfFtEgUKmXyW",
        "outputId": "21529cd5-8c81-44a5-a03e-b98b58125339"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation Matrix:\n",
            "                          number_of_courses_viewed  annual_income  \\\n",
            "number_of_courses_viewed                  1.000000       0.009770   \n",
            "annual_income                             0.009770       1.000000   \n",
            "interaction_count                        -0.023565       0.027036   \n",
            "lead_score                               -0.004879       0.015610   \n",
            "converted                                 0.435914       0.053131   \n",
            "\n",
            "                          interaction_count  lead_score  converted  \n",
            "number_of_courses_viewed          -0.023565   -0.004879   0.435914  \n",
            "annual_income                      0.027036    0.015610   0.053131  \n",
            "interaction_count                  1.000000    0.009888   0.374573  \n",
            "lead_score                         0.009888    1.000000   0.193673  \n",
            "converted                          0.374573    0.193673   1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_1 = df['interaction_count'].corr(df['lead_score'])\n",
        "corr_2 = df['number_of_courses_viewed'].corr(df['lead_score'])\n",
        "corr_3 = df['number_of_courses_viewed'].corr(df['interaction_count'])\n",
        "corr_4 = df['annual_income'].corr(df['interaction_count'])"
      ],
      "metadata": {
        "id": "bS4qwQ8JmccJ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Correlations for given pairs:\")\n",
        "print(f\"interaction_count and lead_score: {corr_1:.6f}\")\n",
        "print(f\"number_of_courses_viewed and lead_score: {corr_2:.6f}\")\n",
        "print(f\"number_of_courses_viewed and interaction_count: {corr_3:.6f}\")\n",
        "print(f\"annual_income and interaction_count: {corr_4:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOWfF67UmejU",
        "outputId": "1087f671-1b75-4fa0-c1a7-5c08cfcca39c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlations for given pairs:\n",
            "interaction_count and lead_score: 0.009888\n",
            "number_of_courses_viewed and lead_score: -0.004879\n",
            "number_of_courses_viewed and interaction_count: -0.023565\n",
            "annual_income and interaction_count: 0.027036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlations = {\n",
        "    'interaction_count and lead_score': abs(corr_1),\n",
        "    'number_of_courses_viewed and lead_score': abs(corr_2),\n",
        "    'number_of_courses_viewed and interaction_count': abs(corr_3),\n",
        "    'annual_income and interaction_count': abs(corr_4)\n",
        "}\n",
        "\n",
        "max_corr_pair = max(correlations, key=correlations.get)\n",
        "print(f\"Pair with biggest correlation (absolute value): {max_corr_pair}\")\n",
        "print(f\"Correlation value: {correlations[max_corr_pair]:.6f}\")\n",
        "print(f\"Answer Q2: {max_corr_pair}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS_MpzbPmhxs",
        "outputId": "1c316274-8013-4279-f20e-130c16f8431f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pair with biggest correlation (absolute value): annual_income and interaction_count\n",
            "Correlation value: 0.027036\n",
            "Answer Q2: annual_income and interaction_count\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Split: 60% train, 20% validation, 20% test"
      ],
      "metadata": {
        "id": "rJWdrx8sozXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First split: 80% full_train, 20% test\n",
        "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Second split: 75% train (60% of original), 25% validation (20% of original)\n",
        "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
        "\n",
        "print(f\"Full dataset: {len(df)} ({100:.1f}%)\")\n",
        "print(f\"Train set: {len(df_train)} ({len(df_train)/len(df)*100:.1f}%)\")\n",
        "print(f\"Validation set: {len(df_val)} ({len(df_val)/len(df)*100:.1f}%)\")\n",
        "print(f\"Test set: {len(df_test)} ({len(df_test)/len(df)*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2mNf-bIo0PM",
        "outputId": "238f6ce1-775a-448e-89cb-8776bbc9b7a2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset: 1462 (100.0%)\n",
            "Train set: 876 (59.9%)\n",
            "Validation set: 293 (20.0%)\n",
            "Test set: 293 (20.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate target variable\n",
        "y_train = df_train['converted'].values\n",
        "y_val = df_val['converted'].values\n",
        "y_test = df_test['converted'].values\n",
        "\n",
        "# Remove target from feature dataframes\n",
        "df_train = df_train.drop('converted', axis=1)\n",
        "df_val = df_val.drop('converted', axis=1)\n",
        "df_test = df_test.drop('converted', axis=1)\n",
        "\n",
        "print(\"Target variable separated and removed from feature sets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBB_Veymo3wx",
        "outputId": "bff0cda0-b78a-40c3-8b3d-6a5949cd1bef"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target variable separated and removed from feature sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q3: Biggest mutual information score"
      ],
      "metadata": {
        "id": "ww2R5zhto_wZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_vars = ['industry', 'location', 'lead_source', 'employment_status']\n",
        "\n",
        "mi_scores = {}\n",
        "for cat_var in categorical_vars:\n",
        "    mi_score = mutual_info_score(df_train[cat_var], y_train)\n",
        "    mi_scores[cat_var] = round(mi_score, 2)\n",
        "    print(f\"Mutual Information Score for '{cat_var}': {mi_scores[cat_var]}\")\n",
        "\n",
        "max_mi_var = max(mi_scores, key=mi_scores.get)\n",
        "print(f\"Variable with biggest MI score: {max_mi_var}\")\n",
        "print(f\"Answer Q3: {max_mi_var}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6zm_uZepIZc",
        "outputId": "3b984989-974b-4a50-8687-8b3e263b54d8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual Information Score for 'industry': 0.01\n",
            "Mutual Information Score for 'location': 0.0\n",
            "Mutual Information Score for 'lead_source': 0.04\n",
            "Mutual Information Score for 'employment_status': 0.01\n",
            "Variable with biggest MI score: lead_source\n",
            "Answer Q3: lead_source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q4: Logistic Regression Accuracy"
      ],
      "metadata": {
        "id": "oJI-YFIqpPbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for logistic regression with one-hot encoding\n",
        "train_dict = df_train.to_dict(orient='records')\n",
        "val_dict = df_val.to_dict(orient='records')\n",
        "\n",
        "# Initialize and fit DictVectorizer\n",
        "dv = DictVectorizer(sparse=False)\n",
        "X_train = dv.fit_transform(train_dict)\n",
        "X_val = dv.transform(val_dict)\n",
        "\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Validation features shape: {X_val.shape}\")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "accuracy_rounded = round(accuracy, 2)\n",
        "\n",
        "print(f\"Validation Accuracy: {accuracy:.6f}\")\n",
        "print(f\"Validation Accuracy (rounded to 2 decimals): {accuracy_rounded}\")\n",
        "print(f\"Answer Q4: {accuracy_rounded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1KXr2Mkpbrr",
        "outputId": "0a6ee454-dc60-41a6-bbdd-4d619ff94a3d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features shape: (876, 31)\n",
            "Validation features shape: (293, 31)\n",
            "Validation Accuracy: 0.699659\n",
            "Validation Accuracy (rounded to 2 decimals): 0.7\n",
            "Answer Q4: 0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q5: Feature elimination"
      ],
      "metadata": {
        "id": "ygWUg8wxpft0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline accuracy from Q4\n",
        "baseline_accuracy = accuracy\n",
        "\n",
        "print(f\"Baseline accuracy: {baseline_accuracy:.6f}\")\n",
        "\n",
        "# Features to test\n",
        "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
        "\n",
        "# Dictionary to store differences\n",
        "accuracy_differences = {}\n",
        "\n",
        "for feature in features_to_test:\n",
        "    # Create copy of train and validation data\n",
        "    df_train_temp = df_train.drop(feature, axis=1)\n",
        "    df_val_temp = df_val.drop(feature, axis=1)\n",
        "\n",
        "    # Convert to dictionaries and transform\n",
        "    train_dict_temp = df_train_temp.to_dict(orient='records')\n",
        "    val_dict_temp = df_val_temp.to_dict(orient='records')\n",
        "\n",
        "    dv_temp = DictVectorizer(sparse=False)\n",
        "    X_train_temp = dv_temp.fit_transform(train_dict_temp)\n",
        "    X_val_temp = dv_temp.transform(val_dict_temp)\n",
        "\n",
        "    # Train model without the feature\n",
        "    model_temp = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
        "    model_temp.fit(X_train_temp, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred_temp = model_temp.predict(X_val_temp)\n",
        "    accuracy_temp = accuracy_score(y_val, y_pred_temp)\n",
        "\n",
        "    # Calculate difference\n",
        "    difference = baseline_accuracy - accuracy_temp\n",
        "    accuracy_differences[feature] = difference\n",
        "\n",
        "    print(f\"Feature: '{feature}'\")\n",
        "    print(f\"  Accuracy without feature: {accuracy_temp:.6f}\")\n",
        "    print(f\"  Difference: {difference:.6f}\")\n",
        "\n",
        "# Find feature with smallest difference (absolute value)\n",
        "min_diff_feature = min(accuracy_differences, key=lambda x: abs(accuracy_differences[x]))\n",
        "print(f\"Feature with smallest difference: '{min_diff_feature}'\")\n",
        "print(f\"This is the least useful feature.\")\n",
        "print(f\"Answer Q5: '{min_diff_feature}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PaA4zXLpnbQ",
        "outputId": "a5c0a0c7-b078-463f-c5e3-f496826276ba"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 0.699659\n",
            "Feature: 'industry'\n",
            "  Accuracy without feature: 0.699659\n",
            "  Difference: 0.000000\n",
            "Feature: 'employment_status'\n",
            "  Accuracy without feature: 0.696246\n",
            "  Difference: 0.003413\n",
            "Feature: 'lead_score'\n",
            "  Accuracy without feature: 0.706485\n",
            "  Difference: -0.006826\n",
            "Feature with smallest difference: 'industry'\n",
            "This is the least useful feature.\n",
            "Answer Q5: 'industry'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q6: Parameter Tuning"
      ],
      "metadata": {
        "id": "XqWRiet7pwr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different C values for regularization\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Use the same data preparation as Q4\n",
        "train_dict = df_train.to_dict(orient='records')\n",
        "val_dict = df_val.to_dict(orient='records')\n",
        "\n",
        "dv = DictVectorizer(sparse=False)\n",
        "X_train = dv.fit_transform(train_dict)\n",
        "X_val = dv.transform(val_dict)\n",
        "\n",
        "# Dictionary to store results\n",
        "c_accuracies = {}\n",
        "\n",
        "print(\"Testing different C values:\")\n",
        "for C in C_values:\n",
        "    # Train model with current C value\n",
        "    model_c = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
        "    model_c.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and calculate accuracy\n",
        "    y_pred_c = model_c.predict(X_val)\n",
        "    accuracy_c = accuracy_score(y_val, y_pred_c)\n",
        "    accuracy_c_rounded = round(accuracy_c, 3)\n",
        "\n",
        "    c_accuracies[C] = accuracy_c_rounded\n",
        "\n",
        "    print(f\"C = {C}\")\n",
        "    print(f\"  Accuracy: {accuracy_c:.6f}\")\n",
        "    print(f\"  Accuracy (rounded to 3 decimals): {accuracy_c_rounded}\")\n",
        "\n",
        "# Find C with best accuracy (if tied, select smallest C)\n",
        "max_accuracy = max(c_accuracies.values())\n",
        "best_c_values = [c for c, acc in c_accuracies.items() if acc == max_accuracy]\n",
        "best_c = min(best_c_values)  # Select smallest C if multiple have same accuracy\n",
        "\n",
        "print(f\"Best accuracy: {max_accuracy}\")\n",
        "print(f\"Best C value: {best_c}\")\n",
        "print(f\"Answer Q6: {best_c}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu4TfSmRpwaz",
        "outputId": "1f2a13be-6d48-4608-b686-9a3992c2986e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing different C values:\n",
            "C = 0.01\n",
            "  Accuracy: 0.699659\n",
            "  Accuracy (rounded to 3 decimals): 0.7\n",
            "C = 0.1\n",
            "  Accuracy: 0.699659\n",
            "  Accuracy (rounded to 3 decimals): 0.7\n",
            "C = 1\n",
            "  Accuracy: 0.699659\n",
            "  Accuracy (rounded to 3 decimals): 0.7\n",
            "C = 10\n",
            "  Accuracy: 0.699659\n",
            "  Accuracy (rounded to 3 decimals): 0.7\n",
            "C = 100\n",
            "  Accuracy: 0.699659\n",
            "  Accuracy (rounded to 3 decimals): 0.7\n",
            "Best accuracy: 0.7\n",
            "Best C value: 0.01\n",
            "Answer Q6: 0.01\n"
          ]
        }
      ]
    }
  ]
}